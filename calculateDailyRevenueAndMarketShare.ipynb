{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate 15 providers daily revenue and market share in that revenue on Reed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate revenue\n",
    "def calculateRevenueAndUnitSold(preDay,nextDay):\n",
    "    \"\"\"Takes two dfs as argument. One is yesterday's data and the other is today's data\"\"\"\n",
    "    preDf = pd.read_csv(f\"{preDay}_15_providers.csv\")\n",
    "    nextDf = pd.read_csv(f\"{nextDay}_15_providers.csv\")\n",
    "    \n",
    "    # Drop all the enquired courses-previous day, since we're only interested in sold courses\n",
    "    toDropPre = preDf[preDf.sold_or_enq.str.contains(\"enquired\")].index\n",
    "    preDf = preDf.drop(toDropPre,axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Drop all the enquired courses-next day\n",
    "    toDropNext = nextDf[nextDf.sold_or_enq.str.contains(\"enquired\")].index\n",
    "    nextDf = nextDf.drop(toDropNext,axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Merge the two dataframes on ids\n",
    "    mergedDf = pd.merge(nextDf,preDf, on=\"id\", how=\"left\",indicator=True)\n",
    "    \n",
    "    # Return data common on both dataframes\n",
    "    mergedBothDf = mergedDf[mergedDf[\"_merge\"]==\"both\"]\n",
    "    \n",
    "    # Column length to insert no of unit sold of course at the at of the dataframe\n",
    "    columnLengthForUnitSold = len(mergedBothDf.columns.values)\n",
    "    \n",
    "    # Create a column name \"unitSold\" between two time duration at the the end of the mergedReqDf\n",
    "    mergedBothDf.insert(loc=columnLengthForUnitSold,value=mergedBothDf.sold_x-mergedBothDf.sold_y, column=\"unitSold\")\n",
    "    \n",
    "    # List to store actual revenue.\n",
    "    # According to Reed, the revenue earned by a provider varies according to following price s\n",
    "    actualRevenue = []\n",
    "    totalMissingOriginalPriceNextDay = mergedBothDf[mergedBothDf.original_price_x.isna()].provider_x.value_counts().sum()\n",
    "    totalMissingOriginalPricePreDay = mergedBothDf[mergedBothDf.original_price_y.isna()].provider_y.value_counts().sum()\n",
    "\n",
    "    if totalMissingOriginalPriceNextDay<totalMissingOriginalPricePreDay:\n",
    "        for prc,sale in zip(mergedBothDf.price_x,mergedBothDf.unitSold):\n",
    "            if 10<=prc<100:\n",
    "                actualRevenue.append(prc*0.4*sale)\n",
    "            elif 100<=prc<150:\n",
    "                actualRevenue.append(prc*0.55*sale)\n",
    "\n",
    "            elif 150<=prc<200:\n",
    "                actualRevenue.append(prc*0.6*sale)\n",
    "\n",
    "            elif 200<=prc<300:\n",
    "                actualRevenue.append(prc*0.7*sale)\n",
    "\n",
    "            elif 300<=prc<500:\n",
    "                actualRevenue.append(prc*0.75*sale)\n",
    "\n",
    "            elif 500<=prc:\n",
    "                actualRevenue.append(prc*0.8*sale)\n",
    "    else:\n",
    "        for prc,sale in zip(mergedBothDf.price_y,mergedBothDf.unitSold):\n",
    "            if 10<=prc<100:\n",
    "                actualRevenue.append(prc*0.4*sale)\n",
    "            elif 100<=prc<150:\n",
    "                actualRevenue.append(prc*0.55*sale)\n",
    "\n",
    "            elif 150<=prc<200:\n",
    "                actualRevenue.append(prc*0.6*sale)\n",
    "\n",
    "            elif 200<=prc<300:\n",
    "                actualRevenue.append(prc*0.7*sale)\n",
    "\n",
    "            elif 300<=prc<500:\n",
    "                actualRevenue.append(prc*0.75*sale)\n",
    "\n",
    "            elif 500<=prc:\n",
    "                actualRevenue.append(prc*0.8*sale)\n",
    "        \n",
    "    # Create a new colum named actual revenue at the end of the current df\n",
    "    columnLengthForActualRevenue = len(mergedBothDf.columns.values)\n",
    "    mergedBothDf.insert(loc=columnLengthForActualRevenue,value=actualRevenue,column=\"actualRevenue\")\n",
    "    \n",
    "    # Group revenue by providers and sort by index (providers name). This is a series object with index name \"provider\"\n",
    "    revenueGroupedByProviders =  mergedBothDf.groupby('provider_x').actualRevenue.sum().round().astype(int).sort_index()\n",
    "    unitSoldGroupedByProviders = mergedBothDf.groupby('provider_x').unitSold.sum().round().astype(int).sort_index()\n",
    "    \n",
    "    # Convert the series to dataframe and make the \"provider\" column again\n",
    "    revenueGroupedByProvidersDf = revenueGroupedByProviders.to_frame().reset_index(level=\"provider_x\")\n",
    "    unitSoldGroupedByProvidersDf = unitSoldGroupedByProviders.to_frame().reset_index(level=\"provider_x\")\n",
    "    \n",
    "    # Make 2 columns named \"individual share of revenue\" and \"individual share of unit sold\"\n",
    "    revenueGroupedByProvidersDf[\"indvShareRevenue\"] = round(revenueGroupedByProvidersDf.actualRevenue/revenueGroupedByProvidersDf.actualRevenue.sum(),4)\n",
    "    unitSoldGroupedByProvidersDf[\"indvShareUnitSold\"] = round(unitSoldGroupedByProvidersDf.unitSold/unitSoldGroupedByProvidersDf.unitSold.sum(),4)\n",
    "    \n",
    "    # Set \"provider\" as index before transposing so that we can insert \"date\" column later\n",
    "    revenueGroupedByProvidersDf = revenueGroupedByProvidersDf.set_index(\"provider_x\")\n",
    "    unitSoldGroupedByProvidersDf = unitSoldGroupedByProvidersDf.set_index(\"provider_x\")\n",
    "    \n",
    "    # Transpost the data. It will create \"provider\" as column from index\n",
    "    revenueGroupedByProvidersDfT = revenueGroupedByProvidersDf.T\n",
    "    unitSoldGroupedByProvidersDfT = unitSoldGroupedByProvidersDf.T\n",
    "    \n",
    "    \"\"\"\n",
    "    1. After transposing, index 0 is the actualRevenue column, and index 1 is the indShareRevenue \n",
    "    column of revenueGroupedByProvidersDfT.\n",
    "    2. And index 0 is the unitSold column, and index 1 in the indShareUnitSold column\n",
    "    of unitSoldGroupedByProvidersDfT.\n",
    "    \"\"\"\n",
    "    # Let's extract the required variables off those 2 dataframes\n",
    "    # Extract actual revenue\n",
    "    extractActualRevenue = revenueGroupedByProvidersDfT.iloc[[0]] # series to dataframe or, to_frame()\n",
    "    \n",
    "    # Extract unitSold\n",
    "    extractUnitSold = unitSoldGroupedByProvidersDfT.iloc[[0]]\n",
    "    \n",
    "    # Extract individual share of revenue\n",
    "    extractIndShareRevenue = revenueGroupedByProvidersDfT.iloc[[1]]\n",
    "    \n",
    "    # Extract individual share of unitSold\n",
    "    extractIndShareUnitSold = unitSoldGroupedByProvidersDfT.iloc[[1]]\n",
    "    \n",
    "    # Insert date column in those 4 dataframes extracted above\n",
    "    extractActualRevenue.insert(loc=0, value=preDay,column=\"date\")\n",
    "    extractUnitSold.insert(loc=0, value=preDay,column=\"date\")\n",
    "    extractIndShareRevenue.insert(loc=0, value=preDay,column=\"date\")\n",
    "    extractIndShareUnitSold.insert(loc=0, value=preDay,column=\"date\")\n",
    "    \n",
    "    \n",
    "    # Insert one more column each named \"combined\" to the 4 dataframes extracted above\n",
    "    # Calculate combined (total of 5 brands) revenue and unit sold\n",
    "    combinedRevenue = extractActualRevenue[\"Course Gate\"]+extractActualRevenue[\"Euston College\"]+extractActualRevenue[\"Janets\"]+extractActualRevenue[\"One Education\"]+extractActualRevenue[\"Training Express Ltd\"]\n",
    "    combinedUnitSold = extractUnitSold[\"Course Gate\"]+extractUnitSold[\"Euston College\"]+extractUnitSold[\"Janets\"]+extractUnitSold[\"One Education\"]+extractUnitSold[\"Training Express Ltd\"]\n",
    "    \n",
    "    # Calculate combined revenue sahre and combined unit sale share \n",
    "    combinedShareRevenue = extractIndShareRevenue[\"Course Gate\"]+extractIndShareRevenue[\"Euston College\"]+extractIndShareRevenue[\"Janets\"]+extractIndShareRevenue[\"One Education\"]+extractIndShareRevenue[\"Training Express Ltd\"]\n",
    "    combinedShareUnitSold = extractIndShareUnitSold[\"Course Gate\"]+extractIndShareUnitSold[\"Euston College\"]+extractIndShareUnitSold[\"Janets\"]+extractIndShareUnitSold[\"One Education\"]+extractIndShareUnitSold[\"Training Express Ltd\"]\n",
    "    \n",
    "    # Insert combined revenue and combined unit sale to the df\n",
    "    extractActualRevenue.insert(loc=1,value=combinedRevenue.sum(),column=\"combined\")\n",
    "    extractUnitSold.insert(loc=1,value=combinedUnitSold.sum(),column=\"combined\")\n",
    "    \n",
    "    # Insert combined revenue share and unit sold share to the df\n",
    "    extractIndShareRevenue.insert(loc=1,value=combinedShareRevenue.sum(),column=\"combined\")\n",
    "    extractIndShareUnitSold.insert(loc=1,value=combinedShareUnitSold.sum(),column=\"combined\")\n",
    "    \n",
    "    \"\"\"first time we need to create a csv file, then we will be appending to those csv files per day\"\"\"\n",
    "#     return extractIndShareRevenue.to_csv('revenueShare.csv',index=None),\\\n",
    "# extractIndShareUnitSold.to_csv('unitSoldShare.csv',index=None),\\\n",
    "# extractActualRevenue.to_csv(\"revenue.csv\",index=None),\\\n",
    "# extractUnitSold.to_csv(\"unitSold.csv\",index=None)\n",
    "    return extractIndShareRevenue.to_csv('revenueShare.csv',mode=\"a\",header=None,index=None),\\\n",
    "    extractIndShareUnitSold.to_csv(\"unitSoldShare.csv\",index=None,mode=\"a\",header=None),\\\n",
    "    extractActualRevenue.to_csv(\"revenue.csv\",index=None,mode=\"a\",header=None),\\\n",
    "    extractUnitSold.to_csv(\"unitSold.csv\",index=None,mode=\"a\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate revenue of 28 Jan. Run this cell onece\n",
    "calculateRevenueAndUnitSold(\"28_Jan\",\"29_Jan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets calculate daywise revenue and unit sale from 29 January to 12 March. And append the value.\n",
    "# Don't run any cell more than once to prevent the append the value with same date more than once.\n",
    "calculateRevenueAndUnitSold(\"17_Mar\",\"18_Mar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average revenue and average market share after n days. These data is also used to make streamlit app that will be deployed to heroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAverageRevenueAndShare():\n",
    "    \"\"\"We are taking no arguments to the function>\n",
    "    It creates 2 output files which will be used to make streamlit app to deploy the app on heroku.\"\"\"\n",
    "    \n",
    "    # Read in revenue and revenue share data\n",
    "    extractIndShareRevenue = pd.read_csv(\"revenueShare.csv\")\n",
    "    extractActualRevenue = pd.read_csv(\"revenue.csv\")\n",
    "    \n",
    "    # Calculate percentage share. Multiply by 100 except date\n",
    "    percentShare = pd.concat([extractIndShareRevenue.date, extractIndShareRevenue.iloc[:,1:]*100],axis=1)\n",
    "\n",
    "    # Set date as index and transpose the df to insert new column \"Average\"\n",
    "    # Now date is the column of makePercentT\n",
    "    percentShareT = percentShare.set_index(\"date\").T\n",
    "\n",
    "    # Insert a column that calculates average revenue after n days\n",
    "    # Insert position is the total number of columns. It inserts at the end of the df\n",
    "    insertionPositionPercent = len(percentShareT.columns.values)\n",
    "    percentShareT.insert(loc= insertionPositionPercent, value = np.round(percentShareT.mean(axis=1),2),column=f\"Avg after {insertionPositionPercent} days\")\n",
    "\n",
    "    # Create avg revenue column\n",
    "    averageRevenue = extractActualRevenue\n",
    "\n",
    "    # Set date as index and transpose the df to insert new column \"Average\"\n",
    "    # Now date is the column of careateAveT\n",
    "    averageRevenueT = averageRevenue.set_index(\"date\").T\n",
    "\n",
    "    # Insert position is the total number of columns\n",
    "    insertionPositionRev = len(averageRevenueT.columns.values)\n",
    "    averageRevenueT.insert(loc= insertionPositionRev, value = np.round(averageRevenueT.mean(axis=1),2),column=f\"Avg after {insertionPositionRev} days\")\n",
    "\n",
    "    # Round those columns values for streamlit plotting\n",
    "    percentShareTR = percentShareT.round(2)\n",
    "    averageRevenueTR = averageRevenueT.round()\n",
    "\n",
    "    # Transpose back to save as csv and make date column again\n",
    "    \"\"\"round actualRevenueHeroku to zero and marketShareHeroku to two decimal points\"\"\"\n",
    "    actualRevenueHeroku = averageRevenueTR.T.reset_index(level=\"date\")\n",
    "    marketShareHeroku = percentShareTR.T.reset_index(level=\"date\")\n",
    "\n",
    "    # overwrite the csv files with clean data\n",
    "    return marketShareHeroku.to_csv(\"marketShareHeroku.csv\",index=None),\\\n",
    "actualRevenueHeroku.to_csv(\"actualRevenueHeroku.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function to create two csv files to make streamlit app\n",
    "calculateAverageRevenueAndShare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
